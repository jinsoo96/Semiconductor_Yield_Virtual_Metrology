{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semiconductor Yield Prediction - EDA & Preprocessing\n",
    "\n",
    "This notebook covers:\n",
    "1. Data Loading & Integration\n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Feature Engineering\n",
    "4. Data Preprocessing\n",
    "\n",
    "**Note:** Common functions are imported from `utils.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import utility functions\n",
    "from utils import *\n",
    "\n",
    "# Additional imports for this notebook\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "path = \"../02_Data/raw/\"\n",
    "train_sensor, train_quality, predict_sensor = load_data(path)\n",
    "\n",
    "print(f\"Train Sensor Shape: {train_sensor.shape}\")\n",
    "print(f\"Train Quality Shape: {train_quality.shape}\")\n",
    "print(f\"Predict Sensor Shape: {predict_sensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create integrated datasets\n",
    "train = make_dataset(train_sensor, train_quality)\n",
    "predict = make_dataset(predict_sensor)\n",
    "\n",
    "print(f\"\\nTrain Shape: {train.shape}\")\n",
    "print(f\"Predict Shape: {predict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics with correlation to target\n",
    "details = describe_(train, 'y')\n",
    "display(details.sort_values(by='corr y', ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for EDA\n",
    "df_eda = train.copy()\n",
    "\n",
    "# Define column groups\n",
    "col_sensor = get_sensor_columns(df_eda)\n",
    "col_time = get_time_columns(df_eda)\n",
    "\n",
    "print(f\"Sensor columns: {len(col_sensor)}\")\n",
    "print(f\"Time columns: {len(col_time)}\")\n",
    "\n",
    "# Get sensor names\n",
    "sensors_nm, lst_sensors = get_sensor_names(col_sensor, LST_STEPS)\n",
    "print(f\"Unique sensors: {len(sensors_nm)}\")\n",
    "\n",
    "# Convert time columns to datetime\n",
    "df_eda[col_time] = df_eda[col_time].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Target Variable Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target distribution analysis\n",
    "QQ_plot(df_eda['y'], 'y')\n",
    "\n",
    "print(f\"\\nTarget Statistics:\")\n",
    "print(f\"Mean: {df_eda['y'].mean():.2f}\")\n",
    "print(f\"Std: {df_eda['y'].std():.2f}\")\n",
    "print(f\"Min: {df_eda['y'].min():.2f}\")\n",
    "print(f\"Max: {df_eda['y'].max():.2f}\")\n",
    "print(f\"\\nOutliers (y < 1240): {len(df_eda[df_eda['y'] < 1240])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Equipment Effect Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate equipment category feature\n",
    "df_eda = gen_cate_feats(df_eda)\n",
    "\n",
    "# Module analysis\n",
    "print(f\"Unique modules: {df_eda['module_name'].nunique()}\")\n",
    "print(f\"Equipment categories: {df_eda['module_name_eq'].unique()}\")\n",
    "\n",
    "# Boxplot by equipment\n",
    "plt.figure(figsize=(12, 5))\n",
    "sns.boxplot(x='module_name_eq', y='y', data=df_eda)\n",
    "plt.title('Quality Index by Equipment Category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Process Duration Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate duration features\n",
    "df_eda = gen_duration_feats(df_eda, LST_STEPSGAP)\n",
    "\n",
    "# Duration statistics\n",
    "col_tmdiff = df_eda.filter(regex='gen_tmdiff($|_\\d)').columns.tolist()\n",
    "\n",
    "def tmdiff_stats(x):\n",
    "    return [round(x.min()/60, 1), round(x.max()/60, 1), round(x.mean()/60, 1)]\n",
    "\n",
    "df_tmp = df_eda[col_tmdiff].apply(tmdiff_stats).T\n",
    "df_tmp.columns = ['MIN (min)', 'MAX (min)', 'MEAN (min)']\n",
    "display(df_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duration vs Quality visualization\n",
    "df_eda.loc[df_eda['gen_tmdiff'] < 1870, 'tmdiff_speed'] = 'E'  # Early\n",
    "df_eda.loc[df_eda['gen_tmdiff'] > 1870, 'tmdiff_speed'] = 'L'  # Late\n",
    "\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(14, 5))\n",
    "sns.scatterplot(x='gen_tmdiff', y='y', hue='tmdiff_speed', data=df_eda, ax=axes[0])\n",
    "sns.scatterplot(x='gen_tmdiff', y='y', hue='module_name_eq', data=df_eda, ax=axes[1])\n",
    "axes[0].set_title('Duration vs Quality (by Speed)')\n",
    "axes[1].set_title('Duration vs Quality (by Equipment)')\n",
    "axes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Sensor Statistical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate statistical features\n",
    "df_eda = gen_stats_feats(df_eda, sensors_nm, LST_STEPS)\n",
    "df_eda = gen_avg_feats(df_eda, sensors_nm, LST_STEPS)\n",
    "\n",
    "# Visualize key statistical features vs target\n",
    "fig, axes = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=(12, 8))\n",
    "fig.subplots_adjust(hspace=.4, wspace=.1)\n",
    "\n",
    "sns.scatterplot(x='gen_hv_para3_std', y='y', data=df_eda, ax=axes[0,0])\n",
    "sns.scatterplot(x='gen_hv_para45_std', y='y', data=df_eda, ax=axes[0,1])\n",
    "sns.scatterplot(x='gen_pressure_para91_std', y='y', data=df_eda, ax=axes[1,0])\n",
    "sns.scatterplot(x='gen_time_para5_std', y='y', data=df_eda, ax=axes[1,1])\n",
    "\n",
    "axes[0,0].set_title('HV Para3 Std vs Quality')\n",
    "axes[0,1].set_title('HV Para45 Std vs Quality')\n",
    "axes[1,0].set_title('Pressure Para91 Std vs Quality')\n",
    "axes[1,1].set_title('Time Para5 Std vs Quality')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for preprocessing\n",
    "df_prep_train = train.copy()\n",
    "df_prep_predict = predict.copy()\n",
    "\n",
    "# Convert time columns\n",
    "df_prep_train[col_time] = df_prep_train[col_time].apply(pd.to_datetime)\n",
    "df_prep_predict[col_time] = df_prep_predict[col_time].apply(pd.to_datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Equipment category features\n",
    "df_prep_train = gen_cate_feats(df_prep_train)\n",
    "df_prep_predict = gen_cate_feats(df_prep_predict)\n",
    "\n",
    "# 2. Clip target outliers\n",
    "print(f\"Before clipping - y range: [{df_prep_train['y'].min():.2f}, {df_prep_train['y'].max():.2f}]\")\n",
    "df_prep_train['y'] = df_prep_train['y'].clip(1240, 1500)\n",
    "print(f\"After clipping - y range: [{df_prep_train['y'].min():.2f}, {df_prep_train['y'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Duration features\n",
    "df_prep_train = gen_duration_feats(df_prep_train, LST_STEPSGAP)\n",
    "df_prep_predict = gen_duration_feats(df_prep_predict, LST_STEPSGAP)\n",
    "\n",
    "# 4. Statistical features (std)\n",
    "df_prep_train = gen_stats_feats(df_prep_train, sensors_nm, LST_STEPS)\n",
    "df_prep_predict = gen_stats_feats(df_prep_predict, sensors_nm, LST_STEPS)\n",
    "\n",
    "# 5. Statistical features (mean)\n",
    "df_prep_train = gen_avg_feats(df_prep_train, sensors_nm, LST_STEPS)\n",
    "df_prep_predict = gen_avg_feats(df_prep_predict, sensors_nm, LST_STEPS)\n",
    "\n",
    "print(f\"Features after engineering: {df_prep_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Speed category\n",
    "df_prep_train.loc[df_prep_train['gen_tmdiff'] < 1870, 'tmdiff_speed'] = 'E'\n",
    "df_prep_train.loc[df_prep_train['gen_tmdiff'] > 1870, 'tmdiff_speed'] = 'L'\n",
    "df_prep_predict.loc[df_prep_predict['gen_tmdiff'] < 1870, 'tmdiff_speed'] = 'E'\n",
    "df_prep_predict.loc[df_prep_predict['gen_tmdiff'] > 1870, 'tmdiff_speed'] = 'L'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Outlier Treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define numerical columns\n",
    "col_numerical = col_sensor + df_prep_train.filter(regex='^gen_').columns.tolist()\n",
    "col_numerical = [c for c in col_numerical if c in df_prep_train.columns]\n",
    "\n",
    "print(f\"Numerical columns to process: {len(col_numerical)}\")\n",
    "\n",
    "# Apply IQR clipping\n",
    "df_prep_train = clipping(df_prep_train, col_numerical)\n",
    "df_prep_predict = clipping(df_prep_predict, col_numerical)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove zero-variance features\n",
    "thresholder = VarianceThreshold(threshold=0)\n",
    "numeric_cols = [c for c in col_numerical if c in df_prep_train.columns]\n",
    "_ = thresholder.fit_transform(df_prep_train[numeric_cols])\n",
    "\n",
    "mask = ~thresholder.get_support()\n",
    "cols_var_drop = np.asarray(numeric_cols)[mask].tolist()\n",
    "\n",
    "print(f\"Features to drop (zero variance): {len(cols_var_drop)}\")\n",
    "if cols_var_drop:\n",
    "    print(f\"Dropped: {cols_var_drop[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Multicollinearity (VIF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate VIF (this may take a few minutes)\n",
    "idx_numerical = [col for col in df_prep_train.columns \n",
    "                 if (df_prep_train[col].dtype == 'float') & ('y' not in col)]\n",
    "\n",
    "print(f\"Calculating VIF for {len(idx_numerical)} features...\")\n",
    "\n",
    "# Note: VIF calculation is computationally expensive\n",
    "# Uncomment below to run (takes ~10 minutes)\n",
    "# vif = calculate_vif(df_prep_train, idx_numerical)\n",
    "# display(vif.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop NA columns\n",
    "df_prep_train.dropna(axis=1, inplace=True)\n",
    "df_prep_predict.dropna(axis=1, inplace=True)\n",
    "\n",
    "# One-hot encode categorical variables\n",
    "df_prep_train, df_prep_predict = prep_cate_feats(df_prep_train, df_prep_predict, 'module_name_eq')\n",
    "df_prep_train, df_prep_predict = prep_cate_feats(df_prep_train, df_prep_predict, 'tmdiff_speed')\n",
    "\n",
    "print(f\"Final train shape: {df_prep_train.shape}\")\n",
    "print(f\"Final predict shape: {df_prep_predict.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature columns\n",
    "col_numeric = [k for k in df_prep_train.columns \n",
    "               if (df_prep_train[k].dtype == 'float') & ('y' not in k)]\n",
    "\n",
    "print(f\"Numeric features available: {len(col_numeric)}\")\n",
    "\n",
    "# SelectKBest with Mutual Information\n",
    "skb = SelectKBest(score_func=mutual_info_regression, k=min(250, len(col_numeric)))\n",
    "skb.fit(df_prep_train[col_numeric], df_prep_train['y'])\n",
    "\n",
    "col_selected = pd.Index(col_numeric)[skb.get_support()].tolist()\n",
    "print(f\"Selected features: {len(col_selected)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define final feature set\n",
    "col_cate = df_prep_train.filter(regex='module_name_eq|tmdiff_speed').columns.tolist()\n",
    "col_X = col_selected + col_cate\n",
    "\n",
    "# Prepare final datasets\n",
    "X_train = df_prep_train[col_X]\n",
    "y_train = df_prep_train['y']\n",
    "X_predict = df_prep_predict[col_X]\n",
    "\n",
    "print(f\"\\nFinal Dataset Summary:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"y_train: {y_train.shape}\")\n",
    "print(f\"X_predict: {X_predict.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data for modeling notebook\n",
    "import pickle\n",
    "\n",
    "preprocessed_data = {\n",
    "    'X_train': X_train,\n",
    "    'y_train': y_train,\n",
    "    'X_predict': X_predict,\n",
    "    'col_X': col_X,\n",
    "    'col_selected': col_selected,\n",
    "    'df_prep_train': df_prep_train,\n",
    "    'df_prep_predict': df_prep_predict\n",
    "}\n",
    "\n",
    "with open('../03_Results/preprocessed_data.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessed_data, f)\n",
    "\n",
    "print(\"Preprocessed data saved to 03_Results/preprocessed_data.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
